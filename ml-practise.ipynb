{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11042372,"sourceType":"datasetVersion","datasetId":6878303},{"sourceId":12706283,"sourceType":"datasetVersion","datasetId":8030431},{"sourceId":12706284,"sourceType":"datasetVersion","datasetId":8030432}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-22T04:07:19.834593Z","iopub.execute_input":"2025-08-22T04:07:19.834880Z","iopub.status.idle":"2025-08-22T04:07:22.835989Z","shell.execute_reply.started":"2025-08-22T04:07:19.834853Z","shell.execute_reply":"2025-08-22T04:07:22.834675Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/titanic-train/titanic_train.csv\n/kaggle/input/ipl-2025-player-lifetime-statistics/cricket_data_2025.csv\n/kaggle/input/house-price/house_price_train.csv\n/kaggle/input/house-price-prediction/house_price_train (1).csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# The file path you found\nfile_path = '/kaggle/input/ipl-2025-player-lifetime-statistics/cricket_data_2025.csv'\n\n# Read the CSV into a pandas DataFrame\ndf = pd.read_csv(file_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T17:26:47.360605Z","iopub.execute_input":"2025-08-07T17:26:47.360929Z","iopub.status.idle":"2025-08-07T17:26:47.396314Z","shell.execute_reply.started":"2025-08-07T17:26:47.360908Z","shell.execute_reply":"2025-08-07T17:26:47.395444Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!git config --global user.email \"seshmanuvarthi27@gmail.com\"\n!git config --global user.name \"Seshmanuvarthi\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T09:16:27.352568Z","iopub.execute_input":"2025-08-03T09:16:27.352906Z","iopub.status.idle":"2025-08-03T09:16:27.601990Z","shell.execute_reply.started":"2025-08-03T09:16:27.352876Z","shell.execute_reply":"2025-08-03T09:16:27.600716Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_selection import VarianceThreshold\n\ndf.shape\n\n[col for col in df.columns if df[col].isnull().sum()>0] #Finding the columns if the have null values\n\ndf['Year'].fillna(int(df['Year'].mean()),inplace=True) #Filling the null columns with mean of that Column \n\ndf['Year'].isnull().sum()\n\nprint(df['Year'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T17:35:35.690768Z","iopub.execute_input":"2025-08-07T17:35:35.691089Z","iopub.status.idle":"2025-08-07T17:35:35.705182Z","shell.execute_reply.started":"2025-08-07T17:35:35.691064Z","shell.execute_reply":"2025-08-07T17:35:35.704175Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y = df['Runs_Scored']  #Predicting Runs_Scored \nX = df[['Matches_Batted', 'Not_Outs', 'Balls_Faced', 'Batting_Strike_Rate', 'Centuries']] \n\nX_train, X_test, y_train, y_test = train_test_split(df.drop(\"Runs_Scored\",axis=1),df['Runs_Scored'], test_size=0.3, random_state=42)\n\nnumeric_cols = X_train.select_dtypes(include=['int64', 'float64'])\n\nconstant_features = [col for col in numeric_cols.columns if X_train[col].std() == 0]\n\nprint(constant_features)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T17:35:38.975056Z","iopub.execute_input":"2025-08-07T17:35:38.975355Z","iopub.status.idle":"2025-08-07T17:35:38.988353Z","shell.execute_reply.started":"2025-08-07T17:35:38.975335Z","shell.execute_reply":"2025-08-07T17:35:38.987382Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df['Empty_Col']=[0]*1008","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T10:33:31.706478Z","iopub.execute_input":"2025-08-03T10:33:31.706822Z","iopub.status.idle":"2025-08-03T10:33:31.711656Z","shell.execute_reply.started":"2025-08-03T10:33:31.706794Z","shell.execute_reply":"2025-08-03T10:33:31.710619Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(df.drop(\"Runs_Scored\",axis=1),df['Runs_Scored'], test_size=0.3, random_state=42)\n\nnumeric_cols = X_train.select_dtypes(include=['int64', 'float64'])\n\nconstant_features = [col for col in numeric_cols if X_train[col].std() == 0]\n\nprint(constant_features)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T17:33:30.677289Z","iopub.execute_input":"2025-08-07T17:33:30.677611Z","iopub.status.idle":"2025-08-07T17:33:30.689054Z","shell.execute_reply.started":"2025-08-07T17:33:30.677588Z","shell.execute_reply":"2025-08-07T17:33:30.688146Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#How to Drop The columns having constant featues \nX_train.drop(labels=constant_features,axis=1,inplace=True)\n\ndf.tail(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T11:08:57.859837Z","iopub.execute_input":"2025-08-03T11:08:57.860159Z","iopub.status.idle":"2025-08-03T11:08:57.879989Z","shell.execute_reply.started":"2025-08-03T11:08:57.860140Z","shell.execute_reply":"2025-08-03T11:08:57.879103Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Quasi_Constant features --> The Columns contains almost the same values \n\nquasi_constant_feature=[]\nfor col in X_train.columns:\n    predominant=(X_train[col].value_counts()/float(len(X_train))).sort_values(ascending=False).values[0] #Calculating the frequency of highest occuuring value in that feature and dividing it wih length of the X_rain DataFrame \n    \n    if predominant >0.989:\n        quasi_constant_feature.append(col)\n\nprint(quasi_constant_feature)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T17:45:26.857444Z","iopub.execute_input":"2025-08-07T17:45:26.857785Z","iopub.status.idle":"2025-08-07T17:45:26.893487Z","shell.execute_reply.started":"2025-08-07T17:45:26.857762Z","shell.execute_reply":"2025-08-07T17:45:26.892473Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T10:55:05.013889Z","iopub.execute_input":"2025-08-03T10:55:05.014167Z","iopub.status.idle":"2025-08-03T10:55:05.020385Z","shell.execute_reply.started":"2025-08-03T10:55:05.014147Z","shell.execute_reply":"2025-08-03T10:55:05.019640Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Duplicate Columns --> Two or More Columns containg exact same values for all the rows.\nduplicate_Cols=[]\n\n#Since there are no duplicate cols in our X_train We create\nX_train['Empty_Col1']=[0]*705\nX_train['Empty_Col2']=[0]*705\n\nfor i in range(len(X_train.columns)):\n    col1=X_train.columns[i]\n    for col2 in X_train.columns[i+1:]:\n        if X_train[col1].equals(X_train[col2]):\n            duplicate_Cols.append(col2)\n\nX_train.drop(labels=duplicate_Cols,axis=1,inplace=True)\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T17:53:22.344992Z","iopub.execute_input":"2025-08-07T17:53:22.345788Z","iopub.status.idle":"2025-08-07T17:53:22.357883Z","shell.execute_reply.started":"2025-08-07T17:53:22.345760Z","shell.execute_reply":"2025-08-07T17:53:22.356765Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(X_train.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T11:09:03.131680Z","iopub.execute_input":"2025-08-03T11:09:03.131981Z","iopub.status.idle":"2025-08-03T11:09:03.144384Z","shell.execute_reply.started":"2025-08-03T11:09:03.131960Z","shell.execute_reply":"2025-08-03T11:09:03.143291Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Correlation --> Show How strong the pairs of features are linearly releated to each other.\nimport matplotlib.pyplot as plt\nimport seaborn as sns \n\nnumeric_data=X_train.select_dtypes(include=['number'])\ncorr_matrix=numeric_data.corr()\n\nplt.figure(figsize=(6,4))\nsns.heatmap(corr_matrix,annot=True,fmt=\".2f\",cmap=\"coolwarm\")\nplt.title(\"Correlation Matrixx\")\nplt.show()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T17:53:49.083087Z","iopub.execute_input":"2025-08-07T17:53:49.083421Z","iopub.status.idle":"2025-08-07T17:53:50.182460Z","shell.execute_reply.started":"2025-08-07T17:53:49.083397Z","shell.execute_reply":"2025-08-07T17:53:50.181734Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(X_train.dtypes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T18:12:42.310672Z","iopub.execute_input":"2025-08-03T18:12:42.311078Z","iopub.status.idle":"2025-08-03T18:12:42.322436Z","shell.execute_reply.started":"2025-08-03T18:12:42.311051Z","shell.execute_reply":"2025-08-03T18:12:42.321244Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd \ndf2=pd.read_csv(\"/kaggle/input/titanic-train/titanic_train.csv\")\n\ndf2.head()\n\ndf2.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T17:20:44.358704Z","iopub.execute_input":"2025-08-21T17:20:44.359882Z","iopub.status.idle":"2025-08-21T17:20:47.186440Z","shell.execute_reply.started":"2025-08-21T17:20:44.359849Z","shell.execute_reply":"2025-08-21T17:20:47.185055Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n      dtype='object')"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"#removing null values from the datasets\ncols_with_null_values=[col for col in df2.columns if df2[col].isnull().sum()>0]\nprint(\"The columns with null-values are\",cols_with_null_values)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T04:27:28.893940Z","iopub.execute_input":"2025-08-08T04:27:28.894440Z","iopub.status.idle":"2025-08-08T04:27:28.904507Z","shell.execute_reply.started":"2025-08-08T04:27:28.894392Z","shell.execute_reply":"2025-08-08T04:27:28.903490Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df2.isna().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T04:39:32.123537Z","iopub.execute_input":"2025-08-08T04:39:32.123874Z","iopub.status.idle":"2025-08-08T04:39:32.132748Z","shell.execute_reply.started":"2025-08-08T04:39:32.123851Z","shell.execute_reply":"2025-08-08T04:39:32.131734Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Filling the columns with null values \n# Assuming Titanic dataset is loaded as `df`\ndf2['Age'].fillna(df2['Age'].median(), inplace=True)\ndf2['Embarked'].fillna(df2['Embarked'].mode()[0],inplace=True)\ndf2['Cabin'].fillna('Unknown',inplace=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T04:33:20.125418Z","iopub.execute_input":"2025-08-08T04:33:20.126342Z","iopub.status.idle":"2025-08-08T04:33:20.132413Z","shell.execute_reply.started":"2025-08-08T04:33:20.126243Z","shell.execute_reply":"2025-08-08T04:33:20.131431Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Finding the constant  featues \n# Find columns with constant values\nconstant_columns = [col for col in df2.columns if df2[col].nunique() == 1]\n\n# Optionally, print the constant columns\nprint(\"Constant columns: \", constant_columns)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T04:50:27.036017Z","iopub.execute_input":"2025-08-08T04:50:27.036408Z","iopub.status.idle":"2025-08-08T04:50:27.047985Z","shell.execute_reply.started":"2025-08-08T04:50:27.036361Z","shell.execute_reply":"2025-08-08T04:50:27.047020Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#finding the quasi-constant features\n\nthreshold = 0.77\nquasi_constant_columns = []\n\nfor col in df2.columns:\n    top_freq = df2[col].value_counts(normalize=True).values[0]\n    if top_freq >= threshold:\n        quasi_constant_columns.append(col)\n\nprint(\"Quasi-constant columns:\", quasi_constant_columns)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T08:57:24.730128Z","iopub.execute_input":"2025-08-16T08:57:24.730329Z","iopub.status.idle":"2025-08-16T08:57:24.800574Z","shell.execute_reply.started":"2025-08-16T08:57:24.730308Z","shell.execute_reply":"2025-08-16T08:57:24.799225Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Finding the duplicate columns\nimport pandas as pd\n\nduplicate_features = []\n\n\ncolumns = df2.columns\n\nfor i in range(len(columns)):\n    for j in range(i + 1, len(columns)):\n        if df2[columns[i]].equals(df2[columns[j]]):\n            duplicate_features.append(columns[j])\n\nprint(\"Duplicate features:\", duplicate_features)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T04:59:35.241141Z","iopub.execute_input":"2025-08-08T04:59:35.241556Z","iopub.status.idle":"2025-08-08T04:59:35.250015Z","shell.execute_reply.started":"2025-08-08T04:59:35.241525Z","shell.execute_reply":"2025-08-08T04:59:35.249115Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n# Select only numeric columns\nnumeric_df = df2.select_dtypes(include=['number'])\n\n# Now compute correlation on numeric columns only\ncorr_matrix = numeric_df.corr()\n\nthreshold = 0.85\nhigh_corr_var = []\n\nupper = corr_matrix.where(~np.tril(np.ones(corr_matrix.shape), k=0).astype(bool))\n\nfor col in upper.columns:\n    for idx in upper.index:\n        corr_val = upper.loc[idx, col]\n        if pd.notnull(corr_val) and abs(corr_val) > threshold:\n            high_corr_var.append((idx, col, corr_val))\n\nfor var1, var2, corr_val in high_corr_var:\n    print(f\"{var1} and {var2} have a correlation of {corr_val:.2f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T05:05:12.239584Z","iopub.execute_input":"2025-08-08T05:05:12.239910Z","iopub.status.idle":"2025-08-08T05:05:12.252613Z","shell.execute_reply.started":"2025-08-08T05:05:12.239886Z","shell.execute_reply":"2025-08-08T05:05:12.251455Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nnumeric_df = df2.select_dtypes(include=['number'])\n\ncorr_matrix = numeric_df.corr()\n\n# Plot heatmap\nplt.figure(figsize=(12, 8))\nsns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', square=True)\nplt.title('Correlation matrix heatmap')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T05:05:18.216315Z","iopub.execute_input":"2025-08-08T05:05:18.216678Z","iopub.status.idle":"2025-08-08T05:05:18.592552Z","shell.execute_reply.started":"2025-08-08T05:05:18.216654Z","shell.execute_reply":"2025-08-08T05:05:18.591598Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.feature_selection import mutual_info_classif\nimport pandas as pd\n\n# 1. Separate features and target\nX = df2.drop(columns=['Survived'])\ny = df2['Survived']\n\n# 2. For mutual_info_classif, input features should be numeric; encode categoricals if needed\n\nX_encoded = pd.get_dummies(X)\n\n# 3. Compute mutual information\nmi_scores = mutual_info_classif(X_encoded, y, discrete_features='auto')\n\n# 4. Create a pandas Series for better visualization\nmi_scores_series = pd.Series(mi_scores, index=X_encoded.columns).sort_values(ascending=False)\n\n# 5. Display the MI scores\nprint(mi_scores_series)\nplt.figure(figsize=(10, 6))\nmi_scores_series.plot(kind='bar')\nplt.title('Mutual Information Scores')\nplt.ylabel('Mutual Information')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T05:06:31.667662Z","iopub.execute_input":"2025-08-08T05:06:31.667965Z","iopub.status.idle":"2025-08-08T05:06:51.886898Z","shell.execute_reply.started":"2025-08-08T05:06:31.667943Z","shell.execute_reply":"2025-08-08T05:06:51.885964Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from scipy.stats import chi2_contingency\nimport pandas as pd\n\n# Example: test association between 'Embarked' and 'Survived'\n\n# Create a contingency table (cross-tab)\ncontingency_table = pd.crosstab(df2['Embarked'], df2['Survived'])\n\n# Perform Chi-Square test\nchi2, p_value, dof, expected = chi2_contingency(contingency_table)\n\nprint(f\"Chi-square statistic: {chi2:.4f}\")\nprint(f\"P-value: {p_value:.4f}\")\n\n# Interpret result\nalpha = 0.05\nif p_value < alpha:\n    print(\"Reject null hypothesis - variables are dependent (associated).\")\nelse:\n    print(\"Fail to reject null hypothesis - variables are independent.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T17:08:04.628380Z","iopub.execute_input":"2025-08-21T17:08:04.628687Z","iopub.status.idle":"2025-08-21T17:08:04.659599Z","shell.execute_reply.started":"2025-08-21T17:08:04.628663Z","shell.execute_reply":"2025-08-21T17:08:04.658614Z"}},"outputs":[{"name":"stdout","text":"Chi-square statistic: 26.4891\nP-value: 0.0000\nReject null hypothesis - variables are dependent (associated).\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"from scipy.stats import f_oneway\nimport pandas as pd\n\n# Example: Check if Age differs by Pclas                                                 \n# Prepare groups\ngroups = []\nfor category in df2['Pclass'].unique():\n    group = df2[df2['Pclass'] == category]['Age'].dropna()  # drop NA in continuous variable\n    groups.append(group)\n\n# Perform ANOVA\nf_stat, p_value = f_oneway(*groups)\n\nprint(f\"F-statistic: {f_stat:.4f}\")\nprint(f\"P-value: {p_value:.4f}\")\n\n# Interpret results\nalpha = 0.05\nif p_value < alpha:\n    print(\"Reject null hypothesis - means differ significantly across groups.\")\nelse:\n    print(\"Fail to reject null hypothesis - means do not differ significantly.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T17:12:11.752210Z","iopub.execute_input":"2025-08-21T17:12:11.752556Z","iopub.status.idle":"2025-08-21T17:12:11.767565Z","shell.execute_reply.started":"2025-08-21T17:12:11.752531Z","shell.execute_reply":"2025-08-21T17:12:11.766451Z"}},"outputs":[{"name":"stdout","text":"F-statistic: 57.4435\nP-value: 0.0000\nReject null hypothesis - means differ significantly across groups.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"print(X.dtypes)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T17:16:54.699721Z","iopub.execute_input":"2025-08-21T17:16:54.700084Z","iopub.status.idle":"2025-08-21T17:16:54.706914Z","shell.execute_reply.started":"2025-08-21T17:16:54.700056Z","shell.execute_reply":"2025-08-21T17:16:54.705804Z"}},"outputs":[{"name":"stdout","text":"PassengerId      int64\nPclass           int64\nName            object\nSex             object\nAge            float64\nSibSp            int64\nParch            int64\nTicket          object\nFare           float64\nCabin           object\nEmbarked        object\ndtype: object\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Select only useful columns (drop Name, Ticket, Cabin, PassengerId)\ndf2_clean = df2[['Survived','Pclass','Sex','Age','SibSp','Parch','Fare','Embarked']].dropna()\n\n# Encode categorical columns into numeric\ndf2_clean = pd.get_dummies(df2_clean, drop_first=True)\n\nX = df2_clean.drop('Survived', axis=1)\ny = df2_clean['Survived']\n\nprint(X.head())        # check features\nprint(X.dtypes)        # ensure all are numeric\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T17:27:17.965338Z","iopub.execute_input":"2025-08-21T17:27:17.965981Z","iopub.status.idle":"2025-08-21T17:27:17.994923Z","shell.execute_reply.started":"2025-08-21T17:27:17.965933Z","shell.execute_reply":"2025-08-21T17:27:17.993488Z"}},"outputs":[{"name":"stdout","text":"   Pclass   Age  SibSp  Parch     Fare  Sex_male  Embarked_Q  Embarked_S\n0       3  22.0      1      0   7.2500      True       False        True\n1       1  38.0      1      0  71.2833     False       False       False\n2       3  26.0      0      0   7.9250     False       False        True\n3       1  35.0      1      0  53.1000     False       False        True\n4       3  35.0      0      0   8.0500      True       False        True\nPclass          int64\nAge           float64\nSibSp           int64\nParch           int64\nFare          float64\nSex_male         bool\nEmbarked_Q       bool\nEmbarked_S       bool\ndtype: object\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom mlxtend.feature_selection import SequentialFeatureSelector as SFS\n\n# Clean dataset\ndf2_clean = df2[['Survived','Pclass','Sex','Age','SibSp','Parch','Fare','Embarked']].dropna()\ndf2_clean = pd.get_dummies(df2_clean, drop_first=True)\n\nX = df2_clean.drop('Survived', axis=1)\ny = df2_clean['Survived']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nlr = LogisticRegression(max_iter=1000)\n\n# Forward Selection\nsfs_forward = SFS(lr, \n                  k_features='best', \n                  forward=True, \n                  floating=False, \n                  scoring='accuracy',\n                  cv=5)\n\nsfs_forward = sfs_forward.fit(X_train, y_train)\nprint(\"Selected features (Forward):\", sfs_forward.k_feature_names_)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T17:20:52.323314Z","iopub.execute_input":"2025-08-21T17:20:52.323676Z","iopub.status.idle":"2025-08-21T17:21:22.712604Z","shell.execute_reply.started":"2025-08-21T17:20:52.323650Z","shell.execute_reply":"2025-08-21T17:21:22.711802Z"}},"outputs":[{"name":"stdout","text":"Selected features (Forward): ('Pclass', 'Age', 'SibSp', 'Sex_male')\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n\nlr = LogisticRegression(max_iter=1000)\n\n# Backward Elimination\nsfs_backward = SFS(lr, \n                   k_features='best', \n                   forward=False,   # backward mode\n                   floating=False, \n                   scoring='accuracy',\n                   cv=5)\n\nsfs_backward = sfs_backward.fit(X_train, y_train)\nprint(\"Selected features (Backward):\", sfs_backward.k_feature_names_)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T17:21:59.537880Z","iopub.execute_input":"2025-08-21T17:21:59.538220Z","iopub.status.idle":"2025-08-21T17:22:51.300002Z","shell.execute_reply.started":"2025-08-21T17:21:59.538198Z","shell.execute_reply":"2025-08-21T17:22:51.296794Z"}},"outputs":[{"name":"stdout","text":"Selected features (Backward): ('Pclass', 'Age', 'SibSp', 'Fare', 'Sex_male', 'Embarked_S')\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"from sklearn.feature_selection import RFE\n\n# Recursive Feature Elimination\nrfe = RFE(lr, n_features_to_select=5)   # choose number of features\nrfe = rfe.fit(X_train, y_train)\n\nprint(\"Selected features (RFE):\", list(X_train.columns[rfe.support_]))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T17:23:02.689994Z","iopub.execute_input":"2025-08-21T17:23:02.690306Z","iopub.status.idle":"2025-08-21T17:23:04.628693Z","shell.execute_reply.started":"2025-08-21T17:23:02.690282Z","shell.execute_reply":"2025-08-21T17:23:04.625811Z"}},"outputs":[{"name":"stdout","text":"Selected features (RFE): ['Pclass', 'SibSp', 'Sex_male', 'Embarked_Q', 'Embarked_S']\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"from mlxtend.feature_selection import ExhaustiveFeatureSelector as EFS\n\n# Exhaustive Feature Selection\nefs = EFS(lr, \n          min_features=1, \n          max_features=X_train.shape[1], \n          scoring='accuracy',\n          cv=5)\n\nefs = efs.fit(X_train, y_train)\n\nprint(\"Selected features (Exhaustive):\", efs.best_feature_names_)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}